# 控制容器对资源的使用率

## Kubernetes 中的资源

对于“资源安全”这个主题而言，遇到的比较典型的问题是**资源超售**，Node 上运行的工作负载使用的资源总量超过了机器自身可用的资源，导致系统内核触发 OOM（Out Of Memory），进而影响服务的稳定性。

这些情况的产生有可能是由于工作负载使用的资源总量超出预期，也有可能是运行的副本数过多，这些情况或多或少都会出现在我们的环境中。

我们知道， Kubernetes 中 Pod 是最小的调度单元。在每个 Pod 中可以包含一个或者多个 container。在每个 Node 上可以运行多个 Pod，但是对于单个 Node 而言，它的资源总量是相对固定的（CPU 和内存等）。控制每个 Pod （或者 container）的资源用量就显得很重要了。

## 控制资源的用量

request 和 limit 是 Kubernetes 用来控制容器 CPU 和内存等资源用量的机制。

### request

request 是容器一定能得到的资源。在 Pod 创建/调度的阶段，Kubernetes 只会将 Pod 调度到能为其提供该资源需求的节点上。

### limit

limit 是确保容器的资源用量一定不超过该配置。

容器实际使用的资源用量如果超过了 request 并不会有什么影响，它还可以使用更多，但是一旦达到了 limit 的限制，那么就不再允许增加了。

## CPU

关于设置 CPU 的 request 时，需要注意的是，如果我们设置的 CPU 的 request 值大于最大节点的核心数，那么你的 Pod 永远无法被调度。

通常情况下，在生产环境，如果你的应用程序并不是专门针对多核心进行了优化，那么建议你将 CPU 的 request 设置在 1 或以下，并通过多副本的方式进行部署，这可以让我们的系统更加灵活和可靠。

但我们在处理 CPU 的 limit 设置时，需要考虑以下内容：

CPU 实际上可以被认为是一个“可压缩”的资源。当应用容器达到 CPU 的 limit 限制时，Kubernetes 会对容器能使用的 CPU 资源进行限制。这带来的问题就是应用程序性能会变差。但是这并不会造成容器的驱逐或者其他的异常。

## 内存

和前面我们提到的 CPU 一样，如果在 request 中声明的内存大于节点上最大的可用内存量，那么你的 Pod 永远无法被调度。

处理内存限制的时候需要注意，内存资源和 CPU 资源是不一样的。内存资源是"不可压缩"的，而且由于没有对应的办法去进行内存的限制， 所以，当实际使用的资源用量超过了它的 limit 限制，那么就会被终止。这是格外需要注意的。

在实际使用过程中，大多数时候，我们并不会仅关注某一个 Pod 的资源用量，更多的是会从项目整体的维度出发。在很多时候，我们会选择通过 Kubernetes 中的 namespace 进行项目间的隔离。那么在 namespace 中是否可以进行资源用量的限制？

## LimitRange

LimitRange 主要是用来控制 namespace 级别的资源用量。它主要能完成如下能力：

- 限制 Pod/container 的最大最小资源用量
- 设置某个 namespace 中的资源的默认 request 和 limit

### 创建 LimiteRange 资源

```yaml
# max-min-default-limit-range.yaml

apiVersion: v1
kind: LimitRange
metadata:
  name: max-min-default-limit-range
spec:
  limits:
  - max:
      cpu: "600m"
    min:
      cpu: "200m"
    defaultRequest:
      cpu: "300m"
    default:
      cpu: "500m"
    type: Container

# kubectl apply -f max-min-default-limit-range.yaml
```

### 验证 LimiteRange 资源效果

```yaml
# vi cpu-overflow.yaml

apiVersion: v1
kind: Pod
metadata:
  labels:
    run: alpine
  name: cpu-overflow
spec:
  containers:
  - args:
    - sleep
    - "9999"
    image: alpine
    name: alpine-1
    resources:
      requests:
        cpu: "300m"
      limits:
        cpu: "800m"
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}

# kubectl apply -f cpu-overflow.yaml
# Error from server (Forbidden): error when creating "cpu-overflow.yaml": pods "cpu-overflow" is forbidden: maximum cpu usage per Container is 600m, but limit is 800m
```

可以看到，Pod 资源创建失败，因为 Pod 中设置的 limit（最大有可能达到的情况）比 LimitRange 中的 max 值更大，所以 Pod 的创建就失败了。

LimitRange 就是一项很典型的 Kubernetes 准入控制（Admission）的实践。

## 总结

为了保证我们的资源安全，不仅仅要对我们自己部署的资源配置 request 和 limit，还应该为其他资源也进行这些配置，以免由于其他服务/应用占用资源过多，导致我们的应用出现问题。所以我们可以通过在 namespace 中增加 LimitRange，不仅可以为 namespace 中部署的资源增加默认值，还可以设置最大、最小值，以此来确保资源的用量都是可控范围中。